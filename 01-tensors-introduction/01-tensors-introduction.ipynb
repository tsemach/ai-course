{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors Operations\n",
    "\n",
    "Tensors are the building block of all PyTotch operations.\\\n",
    "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number.\\\n",
    "\\\n",
    "`Note`: all elements of a tensors require same data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(4.)\n",
    "print(a.shape)  # note: a is a scalar, there is no dimension to scalars.\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6., 7.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([4., 5, 6, 7]) # all of the tensors are set to the same data type\n",
    "print(v.dtype)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([1, 2, 3, 4, 5, 6]) \n",
    "print(v[2:5]) # print items in indexies 2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([1, 2, 3, 4, 5, 6]) \n",
    "print(v[2:]) # print from index 2 until the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.arange(2, 7) # create a vector of 2,3 .. 6 => tensor([2, 3, 4, 5, 6])\n",
    "v = torch.arange(2, 7, 2) # create a vector => tensor([2, 4, 6])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(18).view(3, 2, 3) # create a 3D matrix\n",
    "print(x[1, 0:1, 1:2]) # slice from matrix 1, row 0:1, column 1:2 (excluded)\n",
    "print(x[1, :, :]) # slice from matrix 1, all, all column 1:2 (excluded)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.FloatTensor([1, 2, 3, 4, 5, 6]) # create a float tensor\n",
    "print(v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.FloatTensor([1, 2, 3, 4, 5, 6]) # create a float tensor\n",
    "print(v.view(3, 2)) # rearange to a (3, 2) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.FloatTensor([1, 2, 3, 4, 5, 6]) # create a float tensor\n",
    "print(v.view(3, -1)) # -1 => infer the number of columns, rearange to a (3, 2) matrix, "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1, 2, 3])  # create a vector of [1, 2, 3]\n",
    "v2 = torch.tensor([1, 2, 3]) # create a vector of [1, 2, 3]\n",
    "\n",
    "v1 * v2   # element wise multiplication => tensor([1, 4, 9])\n",
    "v1 * 5    # multiply by scalar => tensor([ 5, 10, 15])\n",
    "torch.dot(v1, v2)         # dot product, v1[0] * v2[0] + v1[1] * v2[1] ... + v1[n] * v2[n] => 14\n",
    "torch.linspace(0, 10, 5)  # dive the spcae of 0:10 to 5 piceses => tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 10, 100)  # dive the spcae of 0:10 to 100 piceses\n",
    "y = torch.exp(x)                # y = exponent of x\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x = torch.arange(0, 1000., 1)\n",
    "x = torch.linspace(0, 10, 100)\n",
    "y1 = torch.exp(x)\n",
    "y2 = torch.exp(torch.max(x) - x)\n",
    "\n",
    "figure, axis = plt.subplots(1, 2)\n",
    "\n",
    "axis[0].plot(x, y1)\n",
    "axis[0].set_title(\"exp(x)\")\n",
    "  \n",
    "# For Cosine Function\n",
    "axis[1].plot(x, y2)\n",
    "axis[1].set_title(\"max(x) = x\")\n",
    "    \n",
    "# Combine all the operations and display\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(18)\n",
    "ms = torch.arange(18).view(3, 3, 2)\n",
    "print(ms)\n",
    "print('max:', torch.max(ms))\n",
    "print(ms[1, 1:2, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 10, 100)\n",
    "\n",
    "y1 = torch.exp(x)\n",
    "y2 = torch.exp(torch.max(x) - x)\n",
    "\n",
    "plt.plot(x.numpy(), y1.numpy())\n",
    "plt.plot(x.numpy(), y2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([1, 2, 3, 4, 5, 6]) # create a float tensor\n",
    "print(v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[5., 6],\n",
    "                  [7, 8],\n",
    "                  [9, 10]])\n",
    "print(m.shape)                  \n",
    "m                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0, 3, 5, 5, 5, 2]).view(2, 3) # create a matrix of dim(2,3)\n",
    "b = torch.tensor([3, 4, 3, -2, 4, -2]).view(3, 2) # create a matrix of dim(3, 2)\n",
    "print(a @ b) # multiply a and b\n",
    "print(torch.matmul(a, b)) # multiply a and b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note`: matrix dimension must be kept on all rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = torch.tensor([\n",
    "  [[111, 112, 113],\n",
    "   [121, 122, 123]],\n",
    "  [[211, 212, 213],\n",
    "   [221, 222, 223.]]])\n",
    "print(d3.shape)\n",
    "d3   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations and gradients\n",
    "We can combine tensors with the usual arithmetic operations. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment. \n",
    "\n",
    "Let's create a new tensor `y` by combining these tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arithmetic operations\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n",
    "\n",
    "To compute the derivatives, we can invoke the `.backward` method on our result `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute derivatives\n",
    "y.backward()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivatives of `y` with respect to the input tensors are stored in the `<tensor>.grad` property of the respective tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display gradients, x = 3, w = 4, b = 5\n",
    "print('dy/dx:', x.grad)   # we didn't defined x with gradiant\n",
    "print('dy/dw:', w.grad)   # the gradient of y with respect of w => w * 1 + 0 = 3\n",
    "print('dy/db:', b.grad)   # the gradient of y with respect of b => w * 0 + 1 = 1 (we trait b as the variable of the derivitve)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`. \n",
    "\n",
    "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f1d363a5d564a07e75a27174019c991e4d9e69e7fd4751dfd8d2b3e541af730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
